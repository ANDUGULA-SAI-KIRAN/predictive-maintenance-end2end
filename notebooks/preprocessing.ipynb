{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b00efaf",
   "metadata": {},
   "source": [
    "### Dependencies imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "934cd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031d451",
   "metadata": {},
   "source": [
    "### 1. Preprocessing Strategy and Experiment Design "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a80c7f",
   "metadata": {},
   "source": [
    "This preprocessing phase is designed to **operationalize insights from EDA** and prepare the dataset for systematic machine learning experimentation. The steps below clearly separate **mandatory preprocessing** from **experimental preprocessing**, ensuring clarity, reproducibility, and fair comparison across modeling approaches.\n",
    "\n",
    "---\n",
    "**1. EDA Summary and Preprocessing Rationale**\n",
    "\n",
    "Exploratory analysis established that:\n",
    "- Machine failures are **rare and highly imbalanced**.\n",
    "- Failure events arise from **localized, non-linear operational regimes** driven by feature interactions and thresholds.\n",
    "- Individual failure mode indicators are **not available at inference time** and therefore cannot be used directly for prediction.\n",
    "- Linear correlations between individual features and the failure target are weak, reinforcing the need for **feature engineering and imbalance-aware modeling strategies**.\n",
    "\n",
    "The primary objective of preprocessing is to:\n",
    "- Clean non-informative and leakage-prone columns\n",
    "- Construct a realistic target variable for machine failure prediction\n",
    "- Prepare multiple feature representations to evaluate their impact on downstream model performance\n",
    "- Ensure that scaling, encoding, and feature selection are applied **in a controlled, pipeline-based manner** to avoid data leakage\n",
    "\n",
    "The preprocessing stage acts as the **bridge between EDA and model development**, while aligning all steps with the **primary evaluation metric**, which will focus on metrics suitable for imbalanced classification (e.g., Recall or PR-AUC).\n",
    "\n",
    "---\n",
    "\n",
    "**2. Mandatory Preprocessing (Applied Once, Common to All Approaches)**\n",
    "\n",
    "The following steps are **non-negotiable** and will be applied uniformly before any experimentation:\n",
    "\n",
    "1. **Remove non-informative identifier columns**\n",
    "   - Drop `id` and `Product ID` as they have no predictive value and may introduce leakage.\n",
    "\n",
    "2. **Target variable construction**\n",
    "   - Create a binary target variable `machine_failure`, where:\n",
    "     - `1` if any of `TWF`, `HDF`, `PWF`, `OSF`, or `RNF` equals 1\n",
    "     - `0` otherwise\n",
    "\n",
    "3. **Leakage prevention**\n",
    "   - Drop individual failure mode columns (`TWF`, `HDF`, `PWF`, `OSF`, `RNF`) after target construction to reflect a realistic deployment scenario.\n",
    "\n",
    "4. **Train–test split**\n",
    "   - Perform a stratified split on `machine_failure` to preserve class imbalance.\n",
    "   - Fix the random seed to ensure reproducibility across experiments.\n",
    "\n",
    "5. **Pipeline-aware preprocessing**\n",
    "   - Apply feature scaling **within model pipelines** only when required by the algorithm to avoid leakage.\n",
    "   - Categorical variables such as `Product Type` will be handled consistently via ordinal encoding since it has ordinal relationship.\n",
    "\n",
    "These steps establish a **clean, consistent, and reproducible baseline dataset**.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Experimental Preprocessing Approaches**\n",
    "\n",
    "After mandatory preprocessing, three experimental approaches will be evaluated. Each approach modifies **only one aspect** of the preprocessing or learning setup, enabling fair comparison.\n",
    "\n",
    "---\n",
    "**Approach 1: Baseline Features with Class Weighting**\n",
    "\n",
    "**Objective:**  \n",
    "Evaluate whether handling class imbalance at the **algorithmic level** is effective without altering the feature space.\n",
    "\n",
    "**Planned Steps:**\n",
    "- Use cleaned, original operational features only.\n",
    "- Apply class weighting during model training to penalize misclassification of failure events.\n",
    "- Apply primarily to models that natively support class weighting (tree-based, linear models).\n",
    "\n",
    "This approach isolates the impact of **loss-level imbalance handling**.\n",
    "\n",
    "---\n",
    "\n",
    "**Approach 2: Domain-Driven Feature Engineering**\n",
    "\n",
    "**Objective:**  \n",
    "Assess whether incorporating physically meaningful, interaction-based features improves failure prediction.\n",
    "\n",
    "**Planned Steps:**\n",
    "- Create derived features informed by EDA:\n",
    "  - **Power** from rotational speed and torque\n",
    "  - **Temperature difference** from process and air temperatures\n",
    "- Retain original features alongside engineered features initially.\n",
    "- Optionally evaluate a reduced feature set to assess information compression versus enrichment.\n",
    "- Ensure all engineered features use **only instantaneous sensor values** to avoid temporal or target leakage.\n",
    "- Encode categorical variables consistently within pipelines.\n",
    "\n",
    "This approach focuses on **feature representation** and allows evaluation of **feature impact** independent of imbalance handling.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Approach 3: Data-Level Imbalance Handling (Resampling)**\n",
    "\n",
    "**Objective:**  \n",
    "Examine whether modifying the training data distribution improves failure detection.\n",
    "\n",
    "**Planned Steps:**\n",
    "- Apply resampling techniques such as:\n",
    "  - Synthetic oversampling (e.g., SMOTE)\n",
    "  - Hybrid methods (e.g., SMOTE with Tomek links)\n",
    "- Apply resampling **only on the training set**, keeping the test set unchanged.\n",
    "- Limit resampling experiments to models compatible with synthetic data (primarily tree-based algorithms).\n",
    "\n",
    "This approach isolates the impact of **data-level imbalance handling** while preserving realistic evaluation conditions.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Experimental Consistency and Evaluation Scope**\n",
    "\n",
    "Across all experimental approaches:\n",
    "- The same train–test split will be used.\n",
    "- The same evaluation metrics will be applied.\n",
    "- Differences in performance will be attributed solely to preprocessing and imbalance-handling choices.\n",
    "\n",
    "This controlled setup ensures **interpretable and defensible conclusions**.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Summary**\n",
    "\n",
    "The preprocessing strategy is intentionally structured into:\n",
    "- **Mandatory preprocessing** to ensure data integrity, realism, and reproducibility\n",
    "- **Experimental preprocessing** to systematically evaluate feature engineering and imbalance-handling strategies\n",
    "\n",
    "This design provides a robust foundation for subsequent **model training, tuning, and explainability analysis**, while maintaining clarity for technical reviewers and stakeholders. Final pipeline selection will additionally consider **performance stability, model complexity, and deployment feasibility**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f6ff0",
   "metadata": {},
   "source": [
    "### 2. Mandatory Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe2cd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:/sai files/projects/predictive-maintenance-end2end/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc256389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['type', 'air_temp', 'process_temp', 'rpm', 'torque', 'tool_wear']\n",
      " Imbalanced data counts train dataset :                  count\n",
      "machine_failure       \n",
      "0                71715\n",
      "1                 1048\n",
      " Imbalanced data counts test dataset :                  count\n",
      "machine_failure       \n",
      "0                17929\n",
      "1                  262\n"
     ]
    }
   ],
   "source": [
    "def mandatory_preprocessing(df: pd.DataFrame, test_size: float = 0.2, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Perform mandatory preprocessing:\n",
    "    - Drop identifiers, Construct binary target, Remove leakage columns, Stratified train-test split, apply ordinal encoding to type\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw dataset including failure columns\n",
    "    test_size : float\n",
    "        Fraction of data for test set\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train, X_test, y_train, y_test : pd.DataFrame / pd.Series\n",
    "        Preprocessed train-test split\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Drop non-informative identifiers ---\n",
    "    df = df.drop(columns=['id', 'Product ID'], errors='ignore')\n",
    "    \n",
    "    # --- 2. Create binary target and drop columns ---\n",
    "    failure_cols = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "    df['machine_failure'] = (df[failure_cols].sum(axis=1)>0).astype(int)    \n",
    "    df = df.drop(columns=failure_cols, errors='ignore')\n",
    "    \n",
    "    # 3. Mapping Low to 0, Medium to 1, and High to 2\n",
    "    quality_mapping = {'L': 0, 'M': 1, 'H': 2}\n",
    "    if 'Type' in df.columns:\n",
    "        df['Type'] = df['Type'].map(quality_mapping)\n",
    "\n",
    "    # 4. rename columns \n",
    "    df.rename(columns={\"Type\":\"type\", \"Air temperature [K]\": \"air_temp\", \"Process temperature [K]\": \"process_temp\", \"Rotational speed [rpm]\": \"rpm\", \n",
    "                       \"Torque [Nm]\": \"torque\", \"Tool wear [min]\": \"tool_wear\"}, inplace=True)\n",
    "\n",
    "    # --- 5. Separate features and target ---\n",
    "    X = df.drop(columns=['machine_failure'])\n",
    "    y = df['machine_failure']\n",
    "    \n",
    "    # --- 6. Stratified train-test split ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = mandatory_preprocessing(df)\n",
    "\n",
    "print(f\"columns: {X_train.columns.to_list()}\")\n",
    "print(f\" Imbalanced data counts train dataset : {pd.DataFrame(y_train.value_counts())}\")\n",
    "print(f\" Imbalanced data counts test dataset : {pd.DataFrame(y_test.value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
